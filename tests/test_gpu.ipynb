{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test specifics\n",
    "\n",
    "Since we need to validate the the output, we have to capture it first. The way jupyter is setup, is that in once cell you set up a capture with `%%capture` magick and then in the next cell you can analyze it. That's why each test group has two cells, the first one doing the action to be tested and the following one doing the validatations.\n",
    "\n",
    "Moreover, the output of this test becomes confusing because the capture mechanism somehow messes things up which leads to re-running the `post_run_cell` callback of of IPyGPULogger again - as a result you get a bogus output with 0's regardless of the code being run. It doesn't interfere with the testing, but it does interfere with things like `.data` which gets reset because of that, showing invalid information - therefore we can only test `.data` w/o capturing the cell's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose\n",
    "from ipygpulogger import IPyGPULogger\n",
    "import ipygpulogger\n",
    "import re, numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_cpu_ram(n): return np.ones((n, n))\n",
    "def consume_gpu_ram(n): return torch.ones((n, n)).cuda()\n",
    "def consume_cpu_ram_128mb():  return consume_cpu_ram(2**12)\n",
    "def consume_gpu_ram_1024mb(): return consume_gpu_ram(2**14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------- #\n",
    "# the following functions work with the captured output\n",
    "# output is captured by `%%capture output` from a cell before\n",
    "\n",
    "# convert .data outputs to the same dimensions (MBs) as reports\n",
    "def b2mbi(x): print(x); return int(x/2**20)\n",
    "\n",
    "# sample:\n",
    "# RAM: Consumed Peaked  Used Total | Exec time 0.046s\n",
    "def check_report_strings(output):\n",
    "    # basic checks\n",
    "    to_match = [r'Consumed', 'Peaked']\n",
    "    for s in to_match: assert re.search(s, output), f\"expecting string: {s}\"\n",
    "\n",
    "# sample:        \n",
    "# CPU:      123    321     2159 MB\n",
    "# GPU:      356    789     2160 MB\n",
    "def get_sizes(output, type):\n",
    "    match = re.findall(type + r': +([\\d\\.]+) +([\\d\\.]+) +([\\d\\.]+) MB', output)\n",
    "    (consumed, peaked, total) = map(float, match[0])\n",
    "    return consumed, peaked, total\n",
    "\n",
    "def get_sizes_cpu(output): return get_sizes(output, \"CPU\")\n",
    "def get_sizes_gpu(output): return get_sizes(output, \"GPU\")\n",
    "\n",
    "# compare reported numbers against expected\n",
    "def check_match(consumed_reported, peaked_reported, \n",
    "                consumed_expected, peaked_expected, abs_tol=0):\n",
    "    assert isclose(consumed_reported, consumed_expected, abs_tol=abs_tol), f\"Consumed RAM reported: {consumed_reported} == real: {consumed_expected}\"\n",
    "    assert isclose(peaked_reported,   peaked_expected,   abs_tol=abs_tol), f\"Peaked RAM reported: {peaked_reported} == real: {peaked_expected}\"\n",
    "\n",
    "# these functions extract the reported data from the output\n",
    "def check_report_cpu(output, consumed_expected, peaked_expected, abs_tol=0):\n",
    "    consumed_reported, peaked_reported, total_reported = get_sizes_cpu(output)\n",
    "    check_match(consumed_reported, peaked_reported, \n",
    "                consumed_expected, peaked_expected, abs_tol)\n",
    "\n",
    "def check_report_gpu(output, consumed_expected, peaked_expected, abs_tol=0):\n",
    "    consumed_reported, peaked_reported, total_reported = get_sizes_gpu(output)\n",
    "    check_match(consumed_reported, peaked_reported, \n",
    "                consumed_expected, peaked_expected, abs_tol)\n",
    "def print_output(output):\n",
    "    print(\"Captured output:\\n\" + \"-\"*50 + \"\\n\" + output + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_version'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_version\"\"\"\n",
    "assert ipygpulogger.__version__, \"version check\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: Consumed Peaked  Used Total | Exec time 0.000s\n",
      "CPU:        0      0     2160 MB |\n",
      "GPU:        0      0     2412 MB |\n"
     ]
    }
   ],
   "source": [
    "if 'il' in locals(): il.stop() # helps debug\n",
    "il = IPyGPULogger().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: Consumed Peaked  Used Total | Exec time 0.403s\n",
      "CPU:        0      0     2288 MB |\n",
      "GPU:        0      0     3436 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "gpu1 = consume_gpu_ram_1024mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "--------------------------------------------------\n",
      "RAM: Consumed Peaked  Used Total | Exec time 0.393s\n",
      "CPU:      128      0     2288 MB |\n",
      "GPU:     1024      0     3436 MB |\n",
      "--------------------------------------------------\n",
      "\n",
      "RAM: Consumed Peaked  Used Total | Exec time 0.008s\n",
      "CPU:        0      0     2160 MB |\n",
      "GPU:    -1024   1024     2412 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_cpu(output, consumed_expected= 128, peaked_expected=0, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=1024, peaked_expected=0, abs_tol=0)\n",
    "\n",
    "# cleanup\n",
    "del cpu1, gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume/release leading to positive peak numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: Consumed Peaked  Used Total | Exec time 0.807s\n",
      "CPU:        0      0     2288 MB |\n",
      "GPU:        0   1024     3436 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "# here we consume 256MB of RAM and release 128MB \n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 2048MB of RAM and release 1024MB\n",
    "# testing: Consumed 1024, Peaked 1024\n",
    "gpu1 = consume_gpu_ram_1024mb()\n",
    "gpu2 = consume_gpu_ram_1024mb()\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "--------------------------------------------------\n",
      "RAM: Consumed Peaked  Used Total | Exec time 0.796s\n",
      "CPU:      128    128     2288 MB |\n",
      "GPU:     1024   1024     3436 MB |\n",
      "--------------------------------------------------\n",
      "\n",
      "RAM: Consumed Peaked  Used Total | Exec time 0.007s\n",
      "CPU:        0      0     2160 MB |\n",
      "GPU:    -1024   1024     2412 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_cpu(output, consumed_expected= 128, peaked_expected= 128, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=1024, peaked_expected=1024, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data accessor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: Consumed Peaked  Used Total | Exec time 0.810s\n",
      "CPU:      128    128     2288 MB |\n",
      "GPU:     1024   1024     3436 MB |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "#assert 5==6, \"really?\"\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: \n",
    "gpu1 = consume_gpu_ram_1024mb()\n",
    "gpu2 = consume_gpu_ram_1024mb()\n",
    "## Consume/Release Positive Peak\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: Consumed Peaked  Used Total | Exec time 0.007s\n",
      "CPU:        0      0     2160 MB |\n",
      "GPU:    -1024   1024     2412 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem, gpu_mem, time_data = il.data\n",
    "\n",
    "check_match(consumed_reported=cpu_mem.used_delta, peaked_reported=cpu_mem.peaked_delta, \n",
    "            consumed_expected=128,                peaked_expected=128,  abs_tol=1)\n",
    "check_match(consumed_reported=gpu_mem.used_delta, peaked_reported=gpu_mem.peaked_delta, \n",
    "            consumed_expected=1024,               peaked_expected=1024, abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stop'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_stop\"\"\"\n",
    "il.stop()\n",
    "#check that no output appears after this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "assert output == \"\", \"there should be no output as logger has been stopped\"\n",
    "\n",
    "# cleanup\n",
    "del cpu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript # prevent committing an unsaved notebook\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
